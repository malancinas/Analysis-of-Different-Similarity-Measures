{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bJR1u6UPABy8",
    "outputId": "ef7ffec8-c6ed-44d8-8499-0920010edb7c"
   },
   "source": [
    "### Map Reduce Paradigm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     C:\\Users\\the-e\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('gutenberg')\n",
    "from nltk.corpus import gutenberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "0yY0clRZADAL"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import time\n",
    "import numpy as np\n",
    "from timeit import default_timer as timer\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from nltk.corpus import brown\n",
    "import scipy.stats as stats\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "9dFqLYAW-EpT"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "#import operator\n",
    "from multiprocessing import Pool\n",
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "tzecUgoW-GAQ"
   },
   "outputs": [],
   "source": [
    "def freqdot(docA,docB): #method to obtain the dotproduct from frequency distribution dictionary\n",
    "    product = 0\n",
    "    for word, count in docA.items():\n",
    "        product += count * docB.get(word,0) #the 0 in .get will use 0 if there is no word in the docB\n",
    "    return product\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "XOnF3arUA9IV"
   },
   "outputs": [],
   "source": [
    "def all_pairs(documents): #creating a list of all documents which dictionaries are input\n",
    "    similarity=[]\n",
    "    temp=[]\n",
    "    for i in range(len(documents)):\n",
    "        temp=[]\n",
    "        for j in range(i+1,len(documents)):\n",
    "            temp.append((i,j))\n",
    "        similarity.append(temp)\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "J6iSZm2xA9RM"
   },
   "outputs": [],
   "source": [
    "fileids= gutenberg.fileids() #Getting all the different book inside the gutenburg corpus in terms of ids\n",
    "docsA= [list(gutenberg.words(i)) for i in fileids] #gutenberg.words alows us to extract all sentences from the gutenberg corpus\n",
    "wordsA = []\n",
    "for d in docsA:\n",
    "    for i in d:\n",
    "        wordsA.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ni6GqwH0A9UR",
    "outputId": "a8155ced-de7e-4c80-effa-2099e3d3680b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (0, 8), (0, 9), (0, 10), (0, 11), (0, 12), (0, 13), (0, 14), (0, 15), (0, 16), (0, 17)], [(1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (1, 7), (1, 8), (1, 9), (1, 10), (1, 11), (1, 12), (1, 13), (1, 14), (1, 15), (1, 16), (1, 17)], [(2, 3), (2, 4), (2, 5), (2, 6), (2, 7), (2, 8), (2, 9), (2, 10), (2, 11), (2, 12), (2, 13), (2, 14), (2, 15), (2, 16), (2, 17)], [(3, 4), (3, 5), (3, 6), (3, 7), (3, 8), (3, 9), (3, 10), (3, 11), (3, 12), (3, 13), (3, 14), (3, 15), (3, 16), (3, 17)], [(4, 5), (4, 6), (4, 7), (4, 8), (4, 9), (4, 10), (4, 11), (4, 12), (4, 13), (4, 14), (4, 15), (4, 16), (4, 17)], [(5, 6), (5, 7), (5, 8), (5, 9), (5, 10), (5, 11), (5, 12), (5, 13), (5, 14), (5, 15), (5, 16), (5, 17)], [(6, 7), (6, 8), (6, 9), (6, 10), (6, 11), (6, 12), (6, 13), (6, 14), (6, 15), (6, 16), (6, 17)], [(7, 8), (7, 9), (7, 10), (7, 11), (7, 12), (7, 13), (7, 14), (7, 15), (7, 16), (7, 17)], [(8, 9), (8, 10), (8, 11), (8, 12), (8, 13), (8, 14), (8, 15), (8, 16), (8, 17)], [(9, 10), (9, 11), (9, 12), (9, 13), (9, 14), (9, 15), (9, 16), (9, 17)], [(10, 11), (10, 12), (10, 13), (10, 14), (10, 15), (10, 16), (10, 17)], [(11, 12), (11, 13), (11, 14), (11, 15), (11, 16), (11, 17)], [(12, 13), (12, 14), (12, 15), (12, 16), (12, 17)], [(13, 14), (13, 15), (13, 16), (13, 17)], [(14, 15), (14, 16), (14, 17)], [(15, 16), (15, 17)], [(16, 17)], []]\n"
     ]
    }
   ],
   "source": [
    "# just for checking\n",
    "docpairs = all_pairs(docsA)\n",
    "print(docpairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "RsaF4I_oBBrH"
   },
   "outputs": [],
   "source": [
    "def mapper(documents): #mapping functions\n",
    "    output=[]\n",
    "    for pair in documents:\n",
    "        output.append((pair[0],pair)) #the first element is used to split the computation and second is which computation it will complete\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Z-trenqsBBtC"
   },
   "outputs": [],
   "source": [
    "def jac_reduce(items):\n",
    "    output=[]\n",
    "    key,value = items #items here is the value obtained from mapper which has (i,[A,B])\n",
    "    for documents in value:\n",
    "        \n",
    "        A=FreqDist(docsA[documents[0]]) #selecting item 1 from the mapped name document\n",
    "        B=FreqDist(docsA[documents[1]]) #selecting item 2 from the mapped name document\n",
    "        #ordinary jaccard similarity\n",
    "        U = A.keys() | B.keys()\n",
    "        I = A.keys() & B.keys()\n",
    "        Jacc = len(I) / len(U)\n",
    "        \n",
    "        output.append(((documents[0],documents[1]),Jacc))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "VT56S6VVBGBm"
   },
   "outputs": [],
   "source": [
    "def cos_reduce(items):\n",
    "    output=[]\n",
    "    key,value = items\n",
    "    for documents in value:\n",
    "        A=FreqDist(docsA[documents[0]]) #selecting item 1 from the mapped name document\n",
    "        B=FreqDist(docsA[documents[1]]) #selecting item 2 from the mapped name document\n",
    "        # ordinary cosine similarity\n",
    "        num = freqdot(A,B) \n",
    "        denom = np.power((freqdot(A,A))*(freqdot(B,B)),0.5)\n",
    "        Cos = num/denom\n",
    "        output.append(((documents[0],documents[1]),Cos))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "bxbrtr87BGDm"
   },
   "outputs": [],
   "source": [
    "\n",
    "def map_reduce_parallel(docum,mapper,reducer,mapprocesses=3,reduceprocesses=2):\n",
    "    output = []\n",
    "    collector=defaultdict(list)  #this dictionary is where we will store intermediate results\n",
    "                                 #it will map keys to lists of values (default value of a list is [])\n",
    "                                 #in a real system, this would be stored in individual files at the map nodes\n",
    "                                 #and then transferred to the reduce nodes\n",
    "    doc1=docum\n",
    "    #map stage\n",
    "    mappool = Pool(processes=mapprocesses)\n",
    "    map_out = mappool.map(mapper,doc1)\n",
    "    mappool.close()\n",
    "    #print map_out\n",
    "    \n",
    "    for mapresult in map_out:\n",
    "        for (key, value) in mapresult:     #pass each input to the mapper function and receive back each key,value pair yielded\n",
    "            collector[key].append(value)     #append the value to the list for that key in the intermediate store\n",
    "            \n",
    "    #reduce stage \n",
    "    reducepool = Pool(processes=reduceprocesses)\n",
    "    #print(type(reducer))\n",
    "    #print(type(collector.items()))\n",
    "    reduceresults=reducepool.map(reducer,collector.items())\n",
    "    reducepool.close()\n",
    "    for reduceresult in reduceresults:\n",
    "        output+=reduceresult\n",
    "   \n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "P36X9BOQBGFr"
   },
   "outputs": [],
   "source": [
    "#checking all documents for the run time\n",
    "def time_parallel(docum,mapper,reducer,style,**args):\n",
    "    #current= 0\n",
    "    times=[]\n",
    "    for i in range(2):\n",
    "        print('Running loop',i) #helps find error\n",
    "        start = timer()\n",
    "        map_reduce_parallel(docum,mapper,reducer,**args)\n",
    "        end = timer()\n",
    "        #current = (end-start)\n",
    "        times.append(end-start)\n",
    "    avg_time = np.mean(times)\n",
    "    print(\"All pair similarity for all gutenberg corpus with {} had average run time {}\".format(style,avg_time))\n",
    "    return avg_time    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Neu3QOcTdtbM"
   },
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "id": "eTHELeoIR7BN"
   },
   "outputs": [],
   "source": [
    "def processfinder(method,i,j): #used to enumerate multiple processes\n",
    "    lst1=[]\n",
    "    lst2=[]\n",
    "    lst3=[]\n",
    "    for a in range(i):\n",
    "        for b in range(j):\n",
    "            lst1.append(a)\n",
    "            lst2.append(b)\n",
    "            lst3.append(float(time_parallel(docpairs,mapper, method,\"Jaccard\",mapprocesses=i,reduceprocesses=j)))\n",
    "      \n",
    "    return lst1,lst2,lst3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UfhIrG7STLoB",
    "outputId": "4fea12a1-fa34-4da1-c5ca-8e79e6f33cb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loop 0\n",
      "Running loop 1\n",
      "All pair similarity for all gutenberg corpus with Jaccard had average run time 30.639299690499683\n",
      "Running loop 0\n",
      "Running loop 1\n",
      "All pair similarity for all gutenberg corpus with Jaccard had average run time 30.78159794400017\n",
      "Running loop 0\n",
      "Running loop 1\n",
      "All pair similarity for all gutenberg corpus with Jaccard had average run time 30.57187984150096\n",
      "Running loop 0\n",
      "Running loop 1\n",
      "All pair similarity for all gutenberg corpus with Jaccard had average run time 30.67204374799894\n",
      "Running loop 0\n",
      "Running loop 1\n",
      "All pair similarity for all gutenberg corpus with Jaccard had average run time 30.766731173001062\n",
      "Running loop 0\n",
      "Running loop 1\n",
      "All pair similarity for all gutenberg corpus with Jaccard had average run time 30.758039680000365\n",
      "Running loop 0\n",
      "Running loop 1\n",
      "All pair similarity for all gutenberg corpus with Jaccard had average run time 30.609995562999757\n",
      "Running loop 0\n",
      "Running loop 1\n",
      "All pair similarity for all gutenberg corpus with Jaccard had average run time 30.58623882250049\n",
      "Running loop 0\n",
      "Running loop 1\n",
      "All pair similarity for all gutenberg corpus with Jaccard had average run time 30.600687447499695\n",
      "Running loop 0\n",
      "Running loop 1\n",
      "All pair similarity for all gutenberg corpus with Jaccard had average run time 30.59425013049986\n",
      "Running loop 0\n",
      "Running loop 1\n",
      "All pair similarity for all gutenberg corpus with Jaccard had average run time 30.681623967499945\n",
      "Running loop 0\n",
      "Running loop 1\n",
      "All pair similarity for all gutenberg corpus with Jaccard had average run time 30.728783473000476\n",
      "Running loop 0\n",
      "Running loop 1\n",
      "All pair similarity for all gutenberg corpus with Jaccard had average run time 30.725392995998845\n",
      "Running loop 0\n",
      "Running loop 1\n",
      "All pair similarity for all gutenberg corpus with Jaccard had average run time 30.508794433999356\n",
      "Running loop 0\n",
      "Running loop 1\n",
      "All pair similarity for all gutenberg corpus with Jaccard had average run time 30.488051680499666\n",
      "Running loop 0\n",
      "Running loop 1\n",
      "All pair similarity for all gutenberg corpus with Jaccard had average run time 30.608843492000233\n"
     ]
    }
   ],
   "source": [
    "a,b,c = processfinder(jac_reduce,4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "N8wxYdyQprHB",
    "outputId": "0d2e62f6-ded7-4866-d580-582c6473a2d7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Map Process count</th>\n",
       "      <th>Reduce Process Count</th>\n",
       "      <th>Average Run Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>30.488052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>30.508794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>30.571880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Map Process count  Reduce Process Count  Average Run Time\n",
       "14                  3                     2         30.488052\n",
       "13                  3                     1         30.508794\n",
       "2                   0                     2         30.571880"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame()\n",
    "df1[\"Map Process count\"] = [i for i in a]\n",
    "df1[\"Reduce Process Count\"] = [i for i in b]\n",
    "df1[\"Average Run Time\"] = [i for i in c]\n",
    "df1.sort_values(by = \"Average Run Time\").head(3) # Only interested in the best performing model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2vaoIkMn3Qmr"
   },
   "source": [
    "After testing all possible cases the fastest calculation of all Jaccard similarity is when I utilise 3 map processes and 2 reduce processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yh6tLszuazk0",
    "outputId": "67e95f04-86c8-486c-e1b3-8be9673c4fe7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loop 0\n",
      "Running loop 1\n",
      "All pair similarity for all gutenberg corpus with Jaccard had average run time 31.208363962000476\n",
      "Running loop 0\n",
      "Running loop 1\n",
      "All pair similarity for all gutenberg corpus with Jaccard had average run time 31.220804969500932\n",
      "Running loop 0\n",
      "Running loop 1\n",
      "All pair similarity for all gutenberg corpus with Jaccard had average run time 31.235590779500853\n",
      "Running loop 0\n",
      "Running loop 1\n",
      "All pair similarity for all gutenberg corpus with Jaccard had average run time 31.0801687485\n",
      "Running loop 0\n",
      "Running loop 1\n",
      "All pair similarity for all gutenberg corpus with Jaccard had average run time 31.118708703000266\n",
      "Running loop 0\n",
      "Running loop 1\n",
      "All pair similarity for all gutenberg corpus with Jaccard had average run time 31.116786405500534\n",
      "Running loop 0\n",
      "Running loop 1\n",
      "All pair similarity for all gutenberg corpus with Jaccard had average run time 31.126346098500107\n",
      "Running loop 0\n",
      "Running loop 1\n",
      "All pair similarity for all gutenberg corpus with Jaccard had average run time 31.03437384100016\n",
      "Running loop 0\n",
      "Running loop 1\n",
      "All pair similarity for all gutenberg corpus with Jaccard had average run time 30.949353312500534\n",
      "Running loop 0\n",
      "Running loop 1\n",
      "All pair similarity for all gutenberg corpus with Jaccard had average run time 31.00753099600024\n",
      "Running loop 0\n",
      "Running loop 1\n",
      "All pair similarity for all gutenberg corpus with Jaccard had average run time 31.06521723249989\n",
      "Running loop 0\n",
      "Running loop 1\n",
      "All pair similarity for all gutenberg corpus with Jaccard had average run time 31.149019272999794\n",
      "Running loop 0\n",
      "Running loop 1\n",
      "All pair similarity for all gutenberg corpus with Jaccard had average run time 31.06470072850061\n",
      "Running loop 0\n",
      "Running loop 1\n",
      "All pair similarity for all gutenberg corpus with Jaccard had average run time 31.10423439349961\n",
      "Running loop 0\n",
      "Running loop 1\n",
      "All pair similarity for all gutenberg corpus with Jaccard had average run time 30.932686920999004\n",
      "Running loop 0\n",
      "Running loop 1\n",
      "All pair similarity for all gutenberg corpus with Jaccard had average run time 30.978400869000325\n"
     ]
    }
   ],
   "source": [
    "d,e,f = processfinder(cos_reduce,4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "kg_dg_BQqfsA",
    "outputId": "8cecd132-9d29-47f4-f9f6-ddad7762fd50"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Map Process count</th>\n",
       "      <th>Reduce Process Count</th>\n",
       "      <th>Average Run Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>30.710155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>30.744845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>30.777759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Map Process count  Reduce Process Count  Average Run Time\n",
       "9                   2                     1         30.710155\n",
       "7                   1                     3         30.744845\n",
       "13                  3                     1         30.777759"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame()\n",
    "df1[\"Map Process count\"] = [i for i in d]\n",
    "df1[\"Reduce Process Count\"] = [i for i in e]\n",
    "df1[\"Average Run Time\"] = [i for i in f]\n",
    "df1.sort_values(by = \"Average Run Time\").head(3) # Only interested in the best performing model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CHHCvtXP38qw"
   },
   "source": [
    "After testing all possible cases the fastest calculation of all Jaccard similarity is when I utilise 2 map processes and 1 reduce processes."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Map Reduce for Jaccard and Cosine",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
